{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données reconnaissance du locuteur (Chirac/Mitterrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données:\n",
    "def load_pres(fname):\n",
    "    alltxts = []\n",
    "    alllabs = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour régler le codage\n",
    "    i=0\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        #\n",
    "        if (i==0) :\n",
    "            print(\"txt init \", txt)\n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
    "        if (i==0) :\n",
    "            print(\"lab\", lab)\n",
    "            print(\"txt\", txt)\n",
    "        if lab.count('M') >0:\n",
    "            alllabs.append(-1)\n",
    "        else: \n",
    "            alllabs.append(1)\n",
    "        alltxts.append(txt)\n",
    "        i+=1\n",
    "    return alltxts,alllabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt init  <100:1:C> Quand je dis chers amis, il ne s'agit pas là d'une formule diplomatique, mais de l'expression de ce que je ressens.\n",
      "\n",
      "lab C\n",
      "\n",
      "txt  Quand je dis chers amis, il ne s'agit pas là d'une formule diplomatique, mais de l'expression de ce que je ressens.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8\"\n",
    "alltxts,alllabs = load_pres(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57413 57413\n",
      " Quand je dis chers amis, il ne s'agit pas là d'une formule diplomatique, mais de l'expression de ce que je ressens.\n",
      "\n",
      "1\n",
      " Je compte sur vous.\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(alltxts),len(alllabs))\n",
    "print(alltxts[0])\n",
    "print(alllabs[0])\n",
    "print(alltxts[-1])\n",
    "print(alllabs[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données classification de sentiments (films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movies(path2data): # 1 classe par répertoire\n",
    "    alltxts = [] # init vide\n",
    "    labs = []\n",
    "    cpt = 0\n",
    "    for cl in os.listdir(path2data): # parcours des fichiers d'un répertoire\n",
    "        for f in os.listdir(path2data+cl):\n",
    "            txt = open(path2data+cl+'/'+f).read()\n",
    "            alltxts.append(txt)\n",
    "            labs.append(cpt)\n",
    "        cpt+=1 # chg répertoire = cht classe\n",
    "        \n",
    "    return alltxts,labs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/movies/movies1000/\"\n",
    "\n",
    "alltxts,alllabs = load_movies(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n",
      "the kids in the hall are an acquired taste . \n",
      "it took at least a season of watching their show on hbo before i became a believer . \n",
      "maybe after watching a half dozen kids in the hall movies , they would grow into the big screen . \n",
      "my recommendation is that , unless you are a big fan of the kids , skip the film . \n",
      "as it is , their first--and most likely only--attempt at a full length film lacks the qualities that made their comedy work on tv . \n",
      "a big-budget and glossy production can not make up for a lack of spontaneity that permeates their tv show . \n",
      "the kids go through the motions , but you get the feeling that they arent really having fun doing so . \n",
      "and this makes it more difficult for the audience to enjoy their antics . \n",
      "brain candy is a bunch of skits tied together by the story of a pharmaceutical company that develops a new drug to cure depression . \n",
      "in typical sketch-comedy tradition , each actor plays several roles . \n",
      "doctor cooper ( kevin mcdonald ) and his team create the drug . \n",
      "then , under pressure from don roritor ( mark mckinney ) , founder and president of roritor pharmaceuticals , dr . cooper releases the drug into the marketplace . \n",
      "the ensuing distribution of the new happy pill throughout the populace drives the rest of the film . \n",
      "at about 90 minutes , brain candy still seems long . \n",
      "the best thing about sketch comedy--and the kids are no exception--is the ability to quickly deliver the laughs , then go on to another quick skit . \n",
      "but with the additional set-up necessary in telling a longer , coherent story , the laughs just dont come fast enough . \n",
      "strangely , the show is even more tame than it was when on cable tv . \n",
      "the movie makes several attempts at risqueness--mostly by pointing up the gayness of one of scott thompsons characters--but they seem almost forced ; as if they have to live up to a pg rating . \n",
      "one of the best bits , though , does make use of thompsons naked buttocks ; we see him charging into battle--going to have sex with some guys taking a shower . \n",
      "in the classic of this genre , monty python pulled off this delicate balancing act between plot advancement and punchline delivery for most of the holy grail . \n",
      "the kids , unfortunately , are not up to the task . \n",
      "there are some amusing moments , to be sure , but not enough to make the experience an enjoyable one . \n",
      "\n",
      "0\n",
      "ingredients : neophyte lawyer , legal situations , corrupt insurance company , \n",
      "synopsis : rudy baylor ( matt damon ) is an ethical kid fresh out of law school who must juggle three legal situations at the same time . \n",
      "rudy's girlfriend is attacked by her violent husband ; rudy's elderly landlady wants to arrange her will so that her children are excluded , and ; the family of rudy's friend with leukemia is suing the corrupt insurance company that wouldn't pay for a bone marrow transplant . \n",
      "rudy is new to being a lawyer and is thoroughly outgunned , but luckily he is aided by a sleazy ambulance chaser ( danny devito ) who has failed the bar exam six times as well as by the kindly presiding judge ( danny glover ) . \n",
      "jon voight plays leo f . drummond , the intimidating and arrogant leader of the all-powerful insurance company's team of lawyers who will do anything to oppose justice . \n",
      "will rudy defeat leo ? \n",
      "will he enjoy being a lawyer ? \n",
      "opinion : the good news is that this movie has a happy ending , and it features a guy trying to do the right thing . \n",
      "director francis ford coppola does this film a little differently than the stereotypical law movie . \n",
      "in the typical lawyer movie there's one big case and the movie focuses on solving it , and somewhere along the line surprise witnesses and motives turn up before the good guy wins ( after lots of gripping courtroom drama ) . \n",
      "however , coppola's movie is deliberately more low key . \n",
      "'the rainmaker' plays out like a personality sketch of young rudy as he gets emotionally involved with and tries to save various little quirky side characters . \n",
      "in the background rudy's voice narrates his feelings and makes half-cynical jokes about the legal profession in general . \n",
      "two factors combine to make this movie less heavy than it can be . \n",
      "first , rudy's time is split juggling three cases , rather than concentrating on a single high-stakes case . \n",
      "also , rudy's use of voice narration in place of acting makes the film lose some of its dramatic edge . \n",
      "the end result is an entertaining low key law movie where the good guys win , and rudy narrates his way into coming of age . \n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(alltxts),len(alllabs))\n",
    "print(alltxts[0])\n",
    "print(alllabs[0])\n",
    "print(alltxts[-1])\n",
    "print(alllabs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Transformation paramétrique du texte (pre-traitements)\n",
    "\n",
    "Vous devez tester, par exemple, les cas suivants:\n",
    "- transformation en minuscule ou pas\n",
    "- suppression de la ponctuation\n",
    "- transformation des mots entièrement en majuscule en marqueurs spécifiques\n",
    "- suppression des chiffres ou pas\n",
    "- conservation d'une partie du texte seulement (seulement la première ligne = titre, seulement la dernière ligne = résumé, ...)\n",
    "- stemming\n",
    "- ...\n",
    "\n",
    "\n",
    "Vérifier systématiquement sur un exemple ou deux le bon fonctionnement des méthodes sur deux documents (au moins un de chaque classe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Extraction du vocabulaire (BoW)\n",
    "\n",
    "- **Exploration préliminaire des jeux de données**\n",
    "    - Quelle est la taille d'origine du vocabulaire?\n",
    "    - Que reste-t-il si on ne garde que les 100 mots les plus fréquents? [word cloud]\n",
    "    - Quels sont les 100 mots dont la fréquence documentaire est la plus grande? [word cloud]\n",
    "    - Quels sont les 100 mots les plus discriminants au sens de odds ratio? [word cloud]\n",
    "    - Quelle est la distribution d'apparition des mots (Zipf)\n",
    "    - Quels sont les 100 bigrammes/trigrammes les plus fréquents?\n",
    "\n",
    "- **Variantes de BoW**\n",
    "    - TF-IDF\n",
    "    - Réduire la taille du vocabulaire (min_df, max_df, max_features)\n",
    "    - BoW binaire\n",
    "    - Bi-grams, tri-grams\n",
    "    - **Quelles performances attendre ? Quels sont les avantages et les inconvénients des ces variantes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Modèles de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Métriques d'évaluation \n",
    "\n",
    "Il faudra utiliser des métriques d'évaluation pertinentes suivant la tâche et l'équilibrage des données : \n",
    "- Accuracy\n",
    "- Courbe ROC, AUC, F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Variantes sur les stratégies d'entraînement\n",
    "\n",
    "- **Sur-apprentissage**. Les techniques sur lesquelles nous travaillons étant sujettes au sur-apprentissage: trouver le paramètre de régularisation dans la documentation et optimiser ce paramètre au sens de la métrique qui vous semble la plus appropriée (cf question précédente).\n",
    "\n",
    " <br>\n",
    "- **Equilibrage des données**. Un problème reconnu comme dur dans la communauté est celui de l'équilibrage des classes (*balance* en anglais). Que faire si les données sont à 80, 90 ou 99% dans une des classes?\n",
    "Le problème est dur mais fréquent; les solutions sont multiples mais on peut isoler 3 grandes familles de solution.\n",
    "\n",
    "1. Ré-équilibrer le jeu de données: supprimer des données dans la classe majoritaire et/ou sur-échantilloner la classe minoritaire.<BR>\n",
    "   $\\Rightarrow$ A vous de jouer pour cette technique\n",
    "1. Changer la formulation de la fonction de coût pour pénaliser plus les erreurs dans la classe minoritaire:\n",
    "soit une fonction $\\Delta$ mesurant les écarts entre $f(x_i)$ et $y_i$ \n",
    "$$C = \\sum_i  \\alpha_i \\Delta(f(x_i),y_i), \\qquad \\alpha_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{si } y_i \\in \\text{classe majoritaire}\\\\\n",
    "B>1 & \\text{si } y_i \\in \\text{classe minoritaire}\\\\\n",
    "\\end{array} \\right.$$\n",
    "<BR>\n",
    "   $\\Rightarrow$ Les SVM et d'autres approches sklearn possèdent des arguments pour régler $B$ ou $1/B$... Ces arguments sont utiles mais pas toujours suffisant.\n",
    "1. Courbe ROC et modification du biais. Une fois la fonction $\\hat y = f(x)$ apprise, il est possible de la *bidouiller* a posteriori: si toutes les prédictions $\\hat y$ sont dans une classe, on va introduire $b$ dans $\\hat y = f(x) + b$ et le faire varier jusqu'à ce qu'un des points change de classe. On peut ensuite aller de plus en plus loin.\n",
    "Le calcul de l'ensemble des scores associés à cette approche mène directement à la courbe ROC.\n",
    "\n",
    "**Note:** certains classifieurs sont intrinsèquement plus résistante au problème d'équilibrage, c'est par exemple le cas des techniques de gradient boosting que vous verrez l'an prochain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Post-processing sur les données Président\n",
    "\n",
    "Pour la tâche de reconnaissance de locuteur, des phrases successives sont souvent associés à un même locuteur. Voir par exemples les 100 premiers labels de la base d'apprentissage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8\"\n",
    "alltxts,alllabs = load_pres(fname)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(range(len(alllabs[0:100]))),alllabs[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Une méthode de post-traitement pour améliorer les résultats consistent à lisser les résultats de la prédictions d'une phrases par les prédictions voisines, en utilisant par exemple une convolution par une filtre Gaussien. Compléter la fonction ci-dessous et tester l'impact de ce lissage sur les performances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_smoothing(pred, size):\n",
    "     # LISSAGE par un filtre Gaussien de taille size - vous pouvez utiliser np.convolve \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Estimer les performances de généralisation d'une méthodes\n",
    "**Ce sera l'enjeu principal du projet : vous disposez d'un ensemble de données, et vous évaluerez les performances sur un ensemble de test auquel vous n'avez pas accès. Il faut donc être capable d'estimer les performances de généralisation du modèles à partir des données d'entraînement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Avant de lancer de grandes expériences, il faut se construire une base de travail solide en étudiant les questions suivantes:\n",
    "\n",
    "- Combien de temps ça prend d'apprendre un classifieur NB/SVM/RegLog sur ces données en fonction de la taille du vocabulaire?\n",
    "- La validation croisée est-elle nécessaire? Est ce qu'on obtient les mêmes résultats avec un simple *split*?\n",
    "- La validation croisée est-elle stable? A partir de combien de fold (travailler avec différentes graines aléatoires et faire des statistiques basiques)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
